# docker run --rm -p 9090:9090 --name prometheus -v /path/to/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml --web.enable-lifecycle
# curl -X POST http://localhost:9090/-/reload


# global:
#   scrape_interval: 15s # By default, scrape targets every 15 seconds.
#   # Attach these labels to any time series or alerts when communicating with
#   # external systems (federation, remote storage, Alertmanager).
#   external_labels:
#     monitor: 'codelab-monitor'

# # A scrape configuration containing exactly one endpoint to scrape:
# # Here it's Prometheus itself.
# scrape_configs:
#   # The job name added as a label `job=<job_name>` to any timeseries scraped
#   - job_name: 'prometheus'
#     # Override the global default and scrape targets from job every 5 seconds.
#     scrape_interval: '5s'
#     static_configs:
#       - targets: ['localhost:9090']

# # Section with default values
# global:
#   scrape_interval: 15s # How frequently to scrape targets from jobs
#   scrape_timeout: 10s # If there is no response from instance do not try to scrape
#   evaluation_interval: 15s # How frequently to evaluate rules (e.g. reload graphs with new data)
# # Prometheus alert manager, left for now

# # Section with default values
# global:
#   scrape_interval: 1s # How frequently to scrape targets from jobs
#   scrape_timeout: 1s # If there is no response from instance do not try to scrape
#   evaluation_interval: 15s # How frequently to evaluate rules (e.g. reload graphs with new data)
# # Prometheus alert manager, left for now
# alerting:
#   alertmanagers:
#   - follow_redirects: true
#     scheme: http
#     timeout: 10s
#     api_version: v2
#     static_configs:
#     - targets: []
# # Specific configuration for jobs
# scrape_configs:
# - job_name: prometheus # Name of the job, can be anything
#   honor_timestamps: true # Use timestamps provided by job
#   scrape_interval: 15s # As before, but for this job
#   scrape_timeout: 10s # ^
#   metrics_path: /metrics # Where metrics are located w.r.t. port (localhost:9090/metrics)
#   scheme: http # Configures the protocol scheme used for requests (localhost is http)
#   follow_redirects: true
#   static_configs:
#   - targets:
#     - localhost:9090

global:
  scrape_interval: '1s'  # By default, scrape targets every 15 seconds.
  external_labels:
    monitor: 'codelab-monitor'

scrape_configs:
  # Prometheus monitoring itself
  - job_name: 'prometheus'
    scrape_interval: '10s'
    static_configs:
      - targets: ['localhost:9090']
  # OS monitoring
  - job_name: 'node'
    scrape_interval: '5s'
    static_configs:
      - targets: ['172.17.0.1:9100']
        labels:
          group: 'production' # notice we have defined two nodes to be labelled in the production environment

  # HBase monitoring
  - job_name: 'hbase'
    static_configs:
      - targets: ['localhost:7000']

  # pgAdmin monitoring
  - job_name: 'pgadmin'
    static_configs:
      - targets: ['localhost:9187']